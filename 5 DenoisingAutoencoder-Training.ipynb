{"cells":[{"cell_type":"markdown","source":["# Training a Denoising Autoencoder\n","\n","Training a UNet to denoise MNIST images.\n","The net is trained on multiple noise levels.\n","\n","We use Technique 3 in [Improved Techniques for Training Score-Based Generative Models](https://arxiv.org/abs/2006.09011).\\\n","I.e. the UNet is trained to predict the unscaled noise, which the paper says removes the need to make the net noise-conditional."],"metadata":{"id":"7KeOEfRbbSlZ"}},{"cell_type":"markdown","metadata":{"id":"J_qkkB_TmXyo"},"source":["## Setup ##"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkALFCGWmXyx"},"outputs":[],"source":["# imports\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","\n","# import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.utils import make_grid\n","\n","from torch.utils.data import DataLoader\n","\n","import numpy as np\n","import random\n","\n","import matplotlib.pyplot as plt\n","plt.rcParams['axes.grid'] = False\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","from IPython import display\n","\n","from google.colab import drive\n","\n","batch_size = 64"]},{"cell_type":"code","source":["training_data = datasets.MNIST(\n","    root='data',\n","    train=True,\n","    download=True,\n","    transform=transforms.ToTensor()\n",")\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)"],"metadata":{"id":"j9_5RP2Co3GY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711030114421,"user_tz":240,"elapsed":2851,"user":{"displayName":"Sabrina Van","userId":"01516518941781044038"}},"outputId":"29a43fcd-371e-4ab4-a823-c77456c34809"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 158535856.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 92540636.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 52393513.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 18513633.40it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["test_data = datasets.MNIST(\n","    root='data',\n","    train=False,\n","    download=True,\n","    transform=transforms.ToTensor()   # floating point, normalized to range [0, 1]\n",")\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)"],"metadata":{"id":"Y0DIpE1ywm4G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Alternate data loader with training data augmentation."],"metadata":{"id":"3_ICckalgkZl"}},{"cell_type":"code","source":["# training_data = datasets.MNIST(\n","#     root='data',\n","#     train=True,\n","#     download=True,\n","#     transform=transforms.Compose([\n","#                       transforms.RandomRotation(15),\n","#                       transforms.Pad(padding=1),\n","#                       transforms.RandomCrop([28, 28]),\n","#                       transforms.ToTensor()\n","#     ])\n","# )"],"metadata":{"id":"i7q3fgPhtUkv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Variant of InstanceNorm that lets through some DC signal.\n","Modified from https://github.com/ermongroup/ncsn"],"metadata":{"id":"JcMgsOH5GFov"}},{"cell_type":"code","source":["class InstanceNorm2dPlus(nn.Module):\n","    def __init__(self, num_features, bias=True):\n","        super().__init__()\n","        self.num_features = num_features\n","        self.bias = bias\n","        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n","        self.alpha = nn.Parameter(torch.zeros(num_features))\n","        self.gamma = nn.Parameter(torch.zeros(num_features))\n","        self.alpha.data.normal_(1, 0.02)\n","        self.gamma.data.normal_(1, 0.02)\n","        if bias:\n","            self.beta = nn.Parameter(torch.zeros(num_features))\n","\n","    def forward(self, x):\n","        means = torch.mean(x, dim=(2, 3))\n","        m = torch.mean(means, dim=-1, keepdim=True)\n","        v = torch.var(means, dim=-1, keepdim=True)\n","        means = (means - m) / (torch.sqrt(v + 1e-5))\n","        h = self.instance_norm(x)\n","\n","        if self.bias:\n","            h = h + means[..., None, None] * self.alpha[..., None, None]\n","            out = self.gamma.view(-1, self.num_features, 1, 1) * h + self.beta.view(-1, self.num_features, 1, 1)\n","        else:\n","            h = h + means[..., None, None] * self.alpha[..., None, None]\n","            out = self.gamma.view(-1, self.num_features, 1, 1) * h\n","        return out"],"metadata":{"id":"6qLozzBLIGot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cs9znl37mXzG"},"source":["## Create UNet ##"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHfzDy9pmXzH"},"outputs":[],"source":["## Your UNet code here\n","# helper operations\n","def conv3x3(in_channels, out_channels):\n","    return nn.Conv2d(in_channels, out_channels,\n","        kernel_size=3, stride=1, padding=1, bias=True)\n","\n","def maxpool2x2():\n","    return nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","class UpConv2x2(nn.Module):\n","    def __init__(self, channels):\n","        super(UpConv2x2, self).__init__()\n","        self.upsample = nn.Upsample(scale_factor=2)\n","        self.conv = nn.Conv2d(channels, channels // 2,\n","            kernel_size=2, stride=1, padding=0, bias=True)\n","\n","    def forward(self, x):\n","        x = self.upsample(x)\n","        x = F.pad(x, (0,1,0,1))\n","        x = self.conv(x)\n","        return x\n","\n","def concat(xh, xv):\n","    return torch.cat([xh, xv], dim=1)\n","\n","\n","# unet blocks\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \"\"\"\n","        Args:\n","            in_channels: number of channels in input (1st) feature map\n","            out_channels: number of channels in output feature maps\n","        \"\"\"\n","        super(ConvBlock, self).__init__()\n","        self.conv1 = conv3x3(in_channels, out_channels)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = conv3x3(out_channels, out_channels)\n","        self.insta1 = InstanceNorm2dPlus(out_channels)\n","        self.insta2 = InstanceNorm2dPlus(out_channels)\n","        self.relu2 = nn.ReLU()\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.insta1(x)\n","        x = self.relu1(x)\n","        x = self.conv2(x)\n","        x = self.insta2(x)\n","        x = self.relu2(x)\n","        return x\n","\n","class DownConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \"\"\"\n","        Args:\n","            in_channels: number of channels in input (1st) feature map\n","            out_channels: number of channels in output feature maps\n","        \"\"\"\n","        super(DownConvBlock, self).__init__()\n","\n","        self.downsample = maxpool2x2()\n","        self.conv = ConvBlock(in_channels, out_channels)\n","\n","    def forward(self, x):\n","        x = self.downsample(x)\n","        x = self.conv(x)\n","\n","        return x\n","\n","class UpConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \"\"\"\n","        Args:\n","            in_channels: number of channels in input (1st) feature map\n","            out_channels: number of channels in output feature maps\n","        \"\"\"\n","        super(UpConvBlock, self).__init__()\n","\n","        self.up = UpConv2x2(in_channels)\n","        self.conv = ConvBlock(in_channels, out_channels)\n","\n","    def forward(self, xh, xv):\n","        \"\"\"\n","        Args:\n","            xv: torch Variable, activations from same resolution feature maps (gray arrow in diagram)\n","            xh: torch Variable, activations from lower resolution feature maps (green arrow in diagram)\n","        \"\"\"\n","        x = self.up(xh)\n","        x = concat(x, xv)\n","        x = self.conv(x)\n","\n","        return x\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        fs = [16,32,64,128,256]\n","        self.conv_in = ConvBlock(1, fs[0])\n","        self.dconv1 = DownConvBlock(fs[0], fs[1])\n","        self.dconv2 = DownConvBlock(fs[1], fs[2])\n","        self.dconv3 = DownConvBlock(fs[2], fs[3])\n","        self.dconv4 = DownConvBlock(fs[3], fs[4])\n","        self.uconv1 = UpConvBlock(fs[4], fs[3])\n","        self.uconv2 = UpConvBlock(fs[3], fs[2])\n","        self.uconv3 = UpConvBlock(fs[2], fs[1])\n","        self.uconv4 = UpConvBlock(fs[1], fs[0])\n","        self.conv_out = conv3x3(fs[0], 1)\n","\n","    def forward(self, x):\n","        x1 = self.conv_in(x)\n","        x2 = self.dconv1(x1)\n","        x3 = self.dconv2(x2)\n","        x4 = self.dconv3(x3)\n","        x5 = self.dconv4(x4)\n","        x = self.uconv1(x5, x4)\n","        x = self.uconv2(x, x3)\n","        x = self.uconv3(x, x2)\n","        x = self.uconv4(x, x1)\n","        x = self.conv_out(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"gBzwuYCwmXzM"},"source":["## Train UNet ##"]},{"cell_type":"code","source":["eta = 0.001\n","nepoch = 50\n","\n","# create net\n","net = UNet()\n","if torch.cuda.is_available():\n","  net.cuda()\n","#net.cpu()\n","lossfn = nn.MSELoss()\n","\n","# create optimizer\n","optimizer = optim.Adam(net.parameters(), lr=eta)"],"metadata":{"id":"rBV9AAJ0bKqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Geometric sequence for scale of noise"],"metadata":{"id":"Dn9shWHpINcU"}},{"cell_type":"code","source":["gamma = (0.01)**0.1\n","sigma = [gamma**i for i in range(11)]"],"metadata":{"id":"Pm6C7OhbbO3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Training loop\n","Monitor validation loss (on test set) at each epoch"],"metadata":{"id":"dJV--kmgMlLs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"peAtnGHimXza","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711032406137,"user_tz":240,"elapsed":516268,"user":{"displayName":"Sabrina Van","userId":"01516518941781044038"}},"outputId":"79a8d6ec-fa4b-49ed-9255-55ac70de89c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(15.9291, device='cuda:0')\n","tensor(14.1403, device='cuda:0')\n","tensor(12.7089, device='cuda:0')\n","tensor(12.0037, device='cuda:0')\n","tensor(11.8619, device='cuda:0')\n","tensor(11.5213, device='cuda:0')\n","tensor(11.6754, device='cuda:0')\n","tensor(11.7264, device='cuda:0')\n","tensor(10.9006, device='cuda:0')\n","tensor(11.1719, device='cuda:0')\n","tensor(10.7108, device='cuda:0')\n","tensor(10.9455, device='cuda:0')\n","tensor(10.7407, device='cuda:0')\n","tensor(10.8185, device='cuda:0')\n","tensor(10.8619, device='cuda:0')\n","tensor(10.4810, device='cuda:0')\n","tensor(10.5030, device='cuda:0')\n","tensor(10.4263, device='cuda:0')\n","tensor(10.5022, device='cuda:0')\n","tensor(10.3624, device='cuda:0')\n","tensor(10.3055, device='cuda:0')\n","tensor(10.4142, device='cuda:0')\n","tensor(10.1961, device='cuda:0')\n","tensor(10.4912, device='cuda:0')\n","tensor(10.3294, device='cuda:0')\n","tensor(10.1823, device='cuda:0')\n","tensor(10.3810, device='cuda:0')\n","tensor(10.1242, device='cuda:0')\n","tensor(10.2391, device='cuda:0')\n","tensor(10.2827, device='cuda:0')\n","tensor(10.3755, device='cuda:0')\n","tensor(10.3340, device='cuda:0')\n","tensor(10.0010, device='cuda:0')\n","tensor(10.0307, device='cuda:0')\n","tensor(10.1539, device='cuda:0')\n","tensor(10.0538, device='cuda:0')\n","tensor(10.1511, device='cuda:0')\n","tensor(9.9785, device='cuda:0')\n","tensor(10.0573, device='cuda:0')\n","tensor(9.8707, device='cuda:0')\n","tensor(10.0569, device='cuda:0')\n","tensor(10.0872, device='cuda:0')\n","tensor(10.0685, device='cuda:0')\n","tensor(9.9713, device='cuda:0')\n","tensor(9.9895, device='cuda:0')\n","tensor(9.9220, device='cuda:0')\n","tensor(9.9226, device='cuda:0')\n","tensor(10.3089, device='cuda:0')\n","tensor(9.7872, device='cuda:0')\n","tensor(9.8559, device='cuda:0')\n"]}],"source":["for epoch in range(nepoch):\n","    for (X, y) in iter(train_dataloader):\n","      X = F.pad(X, (2,2,2,2))  # pad MNIST images from 28x28 to 32x32\n","      X -= 0.5\n","      noise = torch.randn(X.shape)\n","      scale = torch.tensor(random.choices(sigma, k=X.size(0)))\n","      scale = scale.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n","      noisy = X + scale*noise\n","\n","      #X = X.cpu()\n","      #noise = noise.cpu()\n","      #noisy = noisy.cpu()\n","\n","      if torch.cuda.is_available():\n","        X = X.cuda()\n","        noise = noise.cuda()\n","        noisy = noisy.cuda()\n","\n","    # forward, backward, update\n","      optimizer.zero_grad()\n","      pred = net(noisy)\n","      loss = lossfn(pred, - noise)\n","      loss.backward()\n","      optimizer.step()\n","\n","    loss_val = 0\n","    with torch.no_grad():\n","      for (X, y) in iter(test_dataloader):\n","        X = F.pad(X, (2,2,2,2))\n","        X -= 0.5\n","        noise = torch.randn(X.shape)\n","        scale = torch.tensor(random.choices(sigma, k=X.size(0)))\n","        scale = scale.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n","\n","        noisy = X + scale*noise\n","        if torch.cuda.is_available():\n","          X = X.cuda()\n","          noise = noise.cuda()\n","          noisy = noisy.cuda()\n","\n","        #X = X.cpu()\n","        #noise = noise.cpu()\n","        #noisy = noisy.cpu()\n","\n","        pred = net(noisy)\n","        loss_val += lossfn(pred, - noise)\n","\n","      print(loss_val)"]},{"cell_type":"markdown","source":["## Save model for later experiments"],"metadata":{"id":"kl4nlLa_UI3e"}},{"cell_type":"code","source":["drive.mount('/content/gdrive')"],"metadata":{"id":"HiGBBAUgoe_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711032592238,"user_tz":240,"elapsed":21103,"user":{"displayName":"Sabrina Van","userId":"01516518941781044038"}},"outputId":"938ac9a2-dbfc-4ef1-c9ae-23f82b2ce547"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["torch.save(net.state_dict(), 'gdrive/MyDrive/testnoaugment')"],"metadata":{"id":"AXYjPGesonsV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"yy-Dji_COwC7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1PlRSnZFWhmIVuYfpUyUnNPV2wnSrguw6","timestamp":1710860341525}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}